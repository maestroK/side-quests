{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e07588a6",
   "metadata": {},
   "source": [
    "# Scrape and Download Quantum Machine Learning Papers from Nature\n",
    "\n",
    "## Objective\n",
    "This notebook scrapes recent articles on **Quantum Machine Learning (QML)** from Nature, published within the last 7 days, and downloads their PDF versions from arXiv if available. It saves article metadata to a text file and ensures only QML-specific papers are processed.\n",
    "\n",
    "## Theory\n",
    "- **Web Scraping**: Uses `requests` and `BeautifulSoup` to extract article metadata (title, date, URL) from Nature's search results.\n",
    "- **QML Filtering**: Filters articles by requiring both \"quantum\" and ML-related terms (e.g., \"machine learning\", \"qml\") in the title.\n",
    "- **arXiv Integration**: Queries arXiv's API to find PDF versions of papers using their titles.\n",
    "- **Rate Limiting**: Implements delays to avoid server bans."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794dd5d1",
   "metadata": {},
   "source": [
    "- `requests`: For HTTP requests to fetch web pages and PDFs.\n",
    "- `BeautifulSoup`: For parsing HTML/XML content.\n",
    "- `datetime`, `timedelta`: For date filtering (last 7 days).\n",
    "- `quote`: For URL-encoding arXiv queries.\n",
    "- `time`: For rate-limiting delays.\n",
    "- `re`: For sanitizing filenames.\n",
    "- `os`: For file and directory operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b5f8023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime, timedelta\n",
    "from urllib.parse import quote\n",
    "import time\n",
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1450a2ef",
   "metadata": {},
   "source": [
    "- `BASE_URL`: Root URL for Nature.\n",
    "- `SEARCH_URL`: Queries Nature for \"quantum machine learning\" articles from the last 7 days.\n",
    "- `HEADERS`: Mimics a browser to avoid being blocked.\n",
    "- `DELAY`: Ensures polite scraping to prevent rate-limiting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31200ad3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Define constants\n",
    "BASE_URL = \"https://www.nature.com\"\n",
    "SEARCH_URL = f\"{BASE_URL}/search?q=quantum+machine+learning&date_range=last_7_days\"\n",
    "HEADERS = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36\"\n",
    "}\n",
    "DELAY = 2  # Seconds between requests to avoid rate limiting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87757ebb",
   "metadata": {},
   "source": [
    "- Removes invalid characters (e.g., `<`, `:`, `/`) from filenames.\n",
    "- Limits length to 100 characters and appends `.pdf`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cf04fb3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Sanitize filenames for safe saving\n",
    "def sanitize_filename(filename):\n",
    "    \"\"\"Remove invalid characters from filename.\"\"\"\n",
    "    return re.sub(r'[<>:\"/\\\\|?*]', '', filename).strip()[:100] + \".pdf\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "401b9ca7",
   "metadata": {},
   "source": [
    "- Queries arXiv's API with the article title.\n",
    "- Parses the XML response to extract the paper's ID.\n",
    "- Converts the `abs` URL to a `pdf` URL.\n",
    "- Returns `None` if no match is found or an error occurs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc3572df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_arxiv_pdf_url(title):\n",
    "    \"\"\"Search arXiv for PDF version of paper.\"\"\"\n",
    "    try:\n",
    "        time.sleep(DELAY)\n",
    "        base_api = \"http://export.arxiv.org/api/query?\"\n",
    "        query = f'ti:\"{title}\"'\n",
    "        params = {\n",
    "            'search_query': query,\n",
    "            'max_results': 1,\n",
    "            'sortBy': 'submittedDate',\n",
    "            'sortOrder': 'descending'\n",
    "        }\n",
    "        \n",
    "        r = requests.get(base_api, params=params, timeout=10)\n",
    "        r.raise_for_status()\n",
    "        \n",
    "        if \"<entry>\" in r.text:\n",
    "            soup = BeautifulSoup(r.text, 'xml')\n",
    "            entry = soup.find('entry')\n",
    "            if entry:\n",
    "                arxiv_id = entry.find('id').text.strip()\n",
    "                pdf_url = arxiv_id.replace('abs', 'pdf') + '.pdf'\n",
    "                return pdf_url\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error searching arXiv for '{title}': {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90cf1dfe",
   "metadata": {},
   "source": [
    "- Downloads the PDF in chunks to handle large files efficiently.\n",
    "- Saves to a `downloads` directory, creating it if needed.\n",
    "- Returns `True` on success, `False` on failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c5849018",
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_pdf(url, filename):\n",
    "    \"\"\"Download PDF file.\"\"\"\n",
    "    try:\n",
    "        time.sleep(DELAY)\n",
    "        r = requests.get(url, headers=HEADERS, timeout=30, stream=True)\n",
    "        r.raise_for_status()\n",
    "        \n",
    "        # Create downloads directory if it doesn't exist\n",
    "        os.makedirs('downloads', exist_ok=True)\n",
    "        filepath = os.path.join('downloads', filename)\n",
    "        \n",
    "        with open(filepath, 'wb') as f:\n",
    "            for chunk in r.iter_content(8192):\n",
    "                f.write(chunk)\n",
    "        print(f\"‚úÖ Saved PDF: {filename}\")\n",
    "        return True\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Failed to download PDF from {url}: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8550ddb3",
   "metadata": {},
   "source": [
    "- **QML Filter**: Requires both `'quantum'` and one of `['machine learning', 'neural network', 'qml', 'deep learning']` in the title.\n",
    "- **Date Filtering**: Ensures articles are from the last 7 days.\n",
    "- **Error Handling**: Logs specific errors for each article.\n",
    "- **Output**: Saves metadata to `recent_qml_nature_links.txt` and PDFs to a `downloads` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b7d261f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrape_recent_qml_articles():\n",
    "    \"\"\"Scrape recent Quantum Machine Learning articles from Nature.\"\"\"\n",
    "    try:\n",
    "        print(\"üîç Searching for recent Quantum Machine Learning articles...\")\n",
    "        time.sleep(DELAY)\n",
    "        r = requests.get(SEARCH_URL, headers=HEADERS, timeout=10)\n",
    "        r.raise_for_status()\n",
    "        soup = BeautifulSoup(r.text, 'html.parser')\n",
    "\n",
    "        articles = soup.select('.c-card') or soup.select('.app-article-list-row__item')\n",
    "        \n",
    "        if not articles:\n",
    "            print(\"No articles found. Nature's page structure may have changed.\")\n",
    "            return\n",
    "\n",
    "        # Get current date at midnight for accurate comparison\n",
    "        today = datetime.now().replace(hour=0, minute=0, second=0, microsecond=0)\n",
    "        one_week_ago = today - timedelta(days=7)\n",
    "        \n",
    "        output_lines = []\n",
    "        downloaded_count = 0\n",
    "\n",
    "        for item in articles:\n",
    "            try:\n",
    "                title_tag = item.select_one('.c-card__title, .article-item__title')\n",
    "                date_tag = item.select_one('time, [datetime]')\n",
    "                link_tag = item.select_one('a[href^=\"/\"]')\n",
    "\n",
    "                if not all([title_tag, date_tag, link_tag]):\n",
    "                    continue\n",
    "\n",
    "                title = title_tag.text.strip().lower()\n",
    "                \n",
    "                # Stricter QML filter: require 'quantum' and ML-related terms\n",
    "                if ('quantum' in title and \n",
    "                    any(term in title for term in ['machine learning', 'neural network', 'qml', 'deep learning'])):\n",
    "                    date_str = date_tag.get('datetime', '').split('T')[0]\n",
    "                    \n",
    "                    try:\n",
    "                        pub_date = datetime.strptime(date_str, \"%Y-%m-%d\").date()\n",
    "                    except ValueError:\n",
    "                        continue\n",
    "\n",
    "                    # Only process if within date range\n",
    "                    if one_week_ago.date() <= pub_date <= today.date():\n",
    "                        url = BASE_URL + link_tag['href'] if link_tag['href'].startswith('/') else link_tag['href']\n",
    "                        \n",
    "                        print(f\"\\nüì∞ Title: {title}\")\n",
    "                        print(f\"üìÖ Date: {pub_date}\")\n",
    "                        print(f\"üîó URL: {url}\")\n",
    "\n",
    "                        pdf_link = search_arxiv_pdf_url(title)\n",
    "                        if pdf_link:\n",
    "                            print(f\"üÜì arXiv PDF: {pdf_link}\")\n",
    "                            filename = sanitize_filename(title)\n",
    "                            if download_pdf(pdf_link, filename):\n",
    "                                downloaded_count += 1\n",
    "                        else:\n",
    "                            print(\"‚ÑπÔ∏è No arXiv preprint found\")\n",
    "\n",
    "                        output_lines.append(f\"Title: {title}\\nDate: {pub_date}\\nURL: {url}\\n\")\n",
    "                        output_lines.append(f\"arXiv PDF: {pdf_link if pdf_link else 'Not found'}\\n\")\n",
    "                        output_lines.append(\"-\" * 50 + \"\\n\")\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"Error processing article '{title}': {e}\")\n",
    "                continue\n",
    "\n",
    "        if output_lines:\n",
    "            with open(\"recent_qml_nature_links.txt\", \"w\", encoding='utf-8') as f:\n",
    "                f.writelines(output_lines)\n",
    "            print(f\"\\n‚úÖ Saved {len(output_lines)//3} articles to recent_qml_nature_links.txt\")\n",
    "            print(f\"üì• Downloaded {downloaded_count} PDFs\")\n",
    "        else:\n",
    "            print(\"No QML articles found in the last 7 days.\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"Error in main scraping function: {e}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05b4ad66",
   "metadata": {},
   "source": [
    "- Runs the main function to scrape and download QML articles.\n",
    "- Outputs progress to the console and saves results to files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "445d6407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Searching for recent Quantum Machine Learning articles...\n",
      "\n",
      "üì∞ Title: characterizing privacy in quantum machine learning\n",
      "üìÖ Date: 2025-05-19\n",
      "üîó URL: https://www.nature.com/articles/s41534-025-01022-z\n",
      "‚ÑπÔ∏è No arXiv preprint found\n",
      "\n",
      "üì∞ Title: interpretable machine learning for atomic scale magnetic anisotropy in quantum materials\n",
      "üìÖ Date: 2025-05-18\n",
      "üîó URL: https://www.nature.com/articles/s41524-025-01637-y\n",
      "‚ÑπÔ∏è No arXiv preprint found\n",
      "\n",
      "üì∞ Title: quantum neural networks form gaussian processes\n",
      "üìÖ Date: 2025-05-21\n",
      "üîó URL: https://www.nature.com/articles/s41567-025-02883-z\n",
      "üÜì arXiv PDF: http://arxiv.org/pdf/2305.09957v3.pdf\n",
      "‚úÖ Saved PDF: quantum neural networks form gaussian processes.pdf\n",
      "\n",
      "‚úÖ Saved 3 articles to recent_qml_nature_links.txt\n",
      "üì• Downloaded 1 PDFs\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    scrape_recent_qml_articles()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32bb3b77",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
